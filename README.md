# LLM Chat from the command-line

Right now only supports OpenAI Completion API, but later will support more...

# Installation

    pip install chata

# Running

    as

# Setup

    You will need to configure an LLM API.

    For example, if using the OpenAPI Completion API, you should create a .env file which contains your API Key.
    
    See .env.sample for a sample file
